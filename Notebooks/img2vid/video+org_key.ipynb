{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video size: 210x260, FPS: 1.0, Total frames: 20\n",
      "Keypoints available for 116 frames.\n",
      "Output video saved to: /nas/Chingiz/sing_language/code/imgTOvideo/imgTOvideo/01April_2010_Thursday_heute_default-2/20_1/hand_points_overlay.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# ==============================\n",
    "# Configuration (adjust as needed)\n",
    "# ==============================\n",
    "video_path = '/nas/Chingiz/sing_language/code/imgTOvideo/imgTOvideo/01April_2010_Thursday_heute_default-2/20_1/original.mp4'\n",
    "output_video_path = r'/nas/Chingiz/sing_language/code/imgTOvideo/imgTOvideo/01April_2010_Thursday_heute_default-2/20_1/hand_points_overlay.mp4'\n",
    "pkl_path   = r'/nas/Dataset/Phoenix/Chingiz/phoenix-2014-hands-keypoints.pkl'\n",
    "\n",
    "# Set the video key that matches the one in your pickle file.\n",
    "video_key = \"fullFrame-210x260px/train/01April_2010_Thursday_heute_default-2/1/01April_2010_Thursday_heute\"\n",
    "\n",
    "# Confidence threshold: only draw keypoints with confidence above this value.\n",
    "CONF_THRESH = 0.5\n",
    "\n",
    "# ==============================\n",
    "# Load hand keypoints from pickle\n",
    "# ==============================\n",
    "with open(pkl_path, 'rb') as f:\n",
    "    hand_data = pickle.load(f)\n",
    "\n",
    "if video_key not in hand_data:\n",
    "    raise ValueError(f\"Video key '{video_key}' not found in the pickle file.\")\n",
    "\n",
    "# Expected shape: (n_frames, 42, 3)\n",
    "hand_points = hand_data[video_key]['keypoints']\n",
    "\n",
    "# ==============================\n",
    "# Open video file and set up VideoWriter\n",
    "# ==============================\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Error opening video file!\")\n",
    "\n",
    "frame_width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps          = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_count  = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "print(f\"Video size: {frame_width}x{frame_height}, FPS: {fps}, Total frames: {frame_count}\")\n",
    "print(f\"Keypoints available for {hand_points.shape[0]} frames.\")\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# ==============================\n",
    "# Process video frame by frame\n",
    "# ==============================\n",
    "frame_idx = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Check if we have keypoints for the current frame.\n",
    "    if frame_idx < hand_points.shape[0]:\n",
    "        kp_frame = hand_points[frame_idx]  # shape: (42, 3)\n",
    "        for point in kp_frame:\n",
    "            x, y, conf = point\n",
    "            if conf >= CONF_THRESH:\n",
    "                cv2.circle(frame, (int(x), int(y)), radius=3, color=(0, 255, 0), thickness=-1)\n",
    "    \n",
    "    out.write(frame)\n",
    "    \n",
    "    # Display functions are commented out to avoid GUI errors.\n",
    "    # cv2.imshow(\"Hand Points Overlay\", frame)\n",
    "    # if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "    #     break\n",
    "    \n",
    "    frame_idx += 1\n",
    "\n",
    "# ==============================\n",
    "# Clean up\n",
    "# ==============================\n",
    "cap.release()\n",
    "out.release()\n",
    "# Comment out or remove the following line if GUI functions are not supported.\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Output video saved to: {output_video_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video size: 210x260, FPS: 1.0, Total frames: 20\n",
      "Original keypoints available for 116 frames.\n",
      "Quantized keypoints available for 116 frames.\n",
      "Output video saved to: /nas/Chingiz/sing_language/code/imgTOvideo/imgTOvideo/01April_2010_Thursday_heute_default-2/20_1/hand_points_overlay_both.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# ==============================\n",
    "# Configuration (adjust as needed)\n",
    "# ==============================\n",
    "video_path = '/nas/Chingiz/sing_language/code/imgTOvideo/imgTOvideo/01April_2010_Thursday_heute_default-2/20_1/original.mp4'\n",
    "output_video_path = r'/nas/Chingiz/sing_language/code/imgTOvideo/imgTOvideo/01April_2010_Thursday_heute_default-2/20_1/hand_points_overlay_both.mp4'\n",
    "\n",
    "# Path to the original and quantized keypoints pickle files\n",
    "original_pkl_path  = r'/nas/Dataset/Phoenix/Chingiz/phoenix-2014-hands-keypoints.pkl'\n",
    "quantized_pkl_path = r'/nas/Dataset/Phoenix/Chingiz/hoenix-2014-hands-quantized.pkl'\n",
    "\n",
    "# Set the video key that exists in both pickle files.\n",
    "video_key = \"fullFrame-210x260px/train/01April_2010_Thursday_heute_default-2/1/01April_2010_Thursday_heute\"\n",
    "\n",
    "# Confidence threshold: only draw keypoints with confidence above this value.\n",
    "CONF_THRESH = 0.5\n",
    "\n",
    "# ==============================\n",
    "# Load keypoints from both pickle files\n",
    "# ==============================\n",
    "with open(original_pkl_path, 'rb') as f:\n",
    "    original_data = pickle.load(f)\n",
    "\n",
    "with open(quantized_pkl_path, 'rb') as f:\n",
    "    quantized_data = pickle.load(f)\n",
    "\n",
    "if video_key not in original_data:\n",
    "    raise ValueError(f\"Video key '{video_key}' not found in the original pickle file.\")\n",
    "if video_key not in quantized_data:\n",
    "    raise ValueError(f\"Video key '{video_key}' not found in the quantized pickle file.\")\n",
    "\n",
    "# Extract keypoints. Expected shape: (n_frames, 42, 3)\n",
    "orig_kp = original_data[video_key]['keypoints']\n",
    "quant_kp = quantized_data[video_key]['keypoints']\n",
    "\n",
    "# ==============================\n",
    "# Open video file and set up VideoWriter\n",
    "# ==============================\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Error opening video file!\")\n",
    "\n",
    "frame_width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps          = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_count  = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "print(f\"Video size: {frame_width}x{frame_height}, FPS: {fps}, Total frames: {frame_count}\")\n",
    "print(f\"Original keypoints available for {orig_kp.shape[0]} frames.\")\n",
    "print(f\"Quantized keypoints available for {quant_kp.shape[0]} frames.\")\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# ==============================\n",
    "# Process video frame by frame\n",
    "# ==============================\n",
    "frame_idx = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Draw original keypoints (green filled circles)\n",
    "    if frame_idx < orig_kp.shape[0]:\n",
    "        kp_frame_orig = orig_kp[frame_idx]  # shape: (42, 3)\n",
    "        for point in kp_frame_orig:\n",
    "            x, y, conf = point\n",
    "            if conf >= CONF_THRESH:\n",
    "                cv2.circle(frame, (int(x), int(y)), radius=3, color=(0, 255, 0), thickness=-1)\n",
    "    \n",
    "    # Draw quantized keypoints (red circle outlines)\n",
    "    if frame_idx < quant_kp.shape[0]:\n",
    "        kp_frame_quant = quant_kp[frame_idx]  # shape: (42, 3)\n",
    "        for point in kp_frame_quant:\n",
    "            x, y, conf = point\n",
    "            if conf >= CONF_THRESH:\n",
    "                # thickness=2 (not filled) so that red circles are visible around original points.\n",
    "                cv2.circle(frame, (int(x), int(y)), radius=3, color=(0, 0, 255), thickness=2)\n",
    "    \n",
    "    out.write(frame)\n",
    "    \n",
    "    # Since GUI display may not be supported, we comment these lines.\n",
    "    # cv2.imshow(\"Hand Points Overlay (Original + Quantized)\", frame)\n",
    "    # if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "    #     break\n",
    "    \n",
    "    frame_idx += 1\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "# cv2.destroyAllWindows()  # Commented out to avoid GUI errors.\n",
    "\n",
    "print(f\"Output video saved to: {output_video_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video size: 210x260, FPS: 1.0, Total frames: 20\n",
      "Original keypoints available for 116 frames.\n",
      "Quantized keypoints available for 116 frames.\n",
      "Output video with trajectories saved to: /nas/Chingiz/sing_language/code/imgTOvideo/imgTOvideo/01April_2010_Thursday_heute_default-2/20_1/hand_points_overlay_trajectory_quan.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# ==============================\n",
    "# Configuration (adjust as needed)\n",
    "# ==============================\n",
    "video_path = '/nas/Chingiz/sing_language/code/imgTOvideo/imgTOvideo/01April_2010_Thursday_heute_default-2/20_1/original.mp4'\n",
    "output_video_path = r'/nas/Chingiz/sing_language/code/imgTOvideo/imgTOvideo/01April_2010_Thursday_heute_default-2/20_1/hand_points_overlay_trajectory_quan.mp4'\n",
    "original_pkl_path  = r'/nas/Dataset/Phoenix/Chingiz/phoenix-2014-hands-keypoints.pkl'\n",
    "quantized_pkl_path = r'/nas/Dataset/Phoenix/Chingiz/hoenix-2014-hands-quantized.pkl'\n",
    "\n",
    "# Set the video key that exists in both pickle files.\n",
    "video_key = \"fullFrame-210x260px/train/01April_2010_Thursday_heute_default-2/1/01April_2010_Thursday_heute\"\n",
    "\n",
    "# Confidence threshold for drawing keypoints/trajectories.\n",
    "CONF_THRESH = 0.5\n",
    "\n",
    "# ==============================\n",
    "# Load keypoints from both pickle files\n",
    "# ==============================\n",
    "with open(original_pkl_path, 'rb') as f:\n",
    "    original_data = pickle.load(f)\n",
    "\n",
    "with open(quantized_pkl_path, 'rb') as f:\n",
    "    quantized_data = pickle.load(f)\n",
    "\n",
    "if video_key not in original_data:\n",
    "    raise ValueError(f\"Video key '{video_key}' not found in the original pickle file.\")\n",
    "if video_key not in quantized_data:\n",
    "    raise ValueError(f\"Video key '{video_key}' not found in the quantized pickle file.\")\n",
    "\n",
    "# Extract keypoints.\n",
    "# Expected shape: (n_frames, 42, 3)\n",
    "orig_kp = original_data[video_key]['keypoints']\n",
    "quant_kp = quantized_data[video_key]['keypoints']\n",
    "\n",
    "# ==============================\n",
    "# Open video file and set up VideoWriter\n",
    "# ==============================\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Error opening video file!\")\n",
    "\n",
    "frame_width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps          = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_count  = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "print(f\"Video size: {frame_width}x{frame_height}, FPS: {fps}, Total frames: {frame_count}\")\n",
    "print(f\"Original keypoints available for {orig_kp.shape[0]} frames.\")\n",
    "print(f\"Quantized keypoints available for {quant_kp.shape[0]} frames.\")\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# ==============================\n",
    "# Prepare trajectory storage\n",
    "# ==============================\n",
    "# For each of 42 joints, maintain a list of points for original and quantized keypoints.\n",
    "orig_trajectories = {j: [] for j in range(42)}\n",
    "quant_trajectories = {j: [] for j in range(42)}\n",
    "\n",
    "# ==============================\n",
    "# Process video frame by frame and draw trajectories\n",
    "# ==============================\n",
    "frame_idx = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Process original keypoints (green)\n",
    "    if frame_idx < orig_kp.shape[0]:\n",
    "        kp_frame_orig = orig_kp[frame_idx]  # shape: (42, 3)\n",
    "        for j, point in enumerate(kp_frame_orig):\n",
    "            x, y, conf = point\n",
    "            if conf >= CONF_THRESH:\n",
    "                pt = (int(x), int(y))\n",
    "                orig_trajectories[j].append(pt)\n",
    "                # Draw the trajectory as a polyline if there are at least 2 points.\n",
    "                if len(orig_trajectories[j]) >= 2:\n",
    "                    pts_array = np.array(orig_trajectories[j], np.int32).reshape((-1, 1, 2))\n",
    "                    cv2.polylines(frame, [pts_array], isClosed=False, color=(0, 255, 0), thickness=1)\n",
    "                # Draw current keypoint.\n",
    "                cv2.circle(frame, pt, radius=3, color=(0, 255, 0), thickness=-1)\n",
    "    \n",
    "    # Process quantized keypoints (red)\n",
    "    if frame_idx < quant_kp.shape[0]:\n",
    "        kp_frame_quant = quant_kp[frame_idx]  # shape: (42, 3)\n",
    "        for j, point in enumerate(kp_frame_quant):\n",
    "            x, y, conf = point\n",
    "            if conf >= CONF_THRESH:\n",
    "                pt = (int(x), int(y))\n",
    "                quant_trajectories[j].append(pt)\n",
    "                # Draw the trajectory as a polyline if there are at least 2 points.\n",
    "                if len(quant_trajectories[j]) >= 2:\n",
    "                    pts_array = np.array(quant_trajectories[j], np.int32).reshape((-1, 1, 2))\n",
    "                    cv2.polylines(frame, [pts_array], isClosed=False, color=(0, 0, 255), thickness=1)\n",
    "                # Draw current keypoint.\n",
    "                cv2.circle(frame, pt, radius=3, color=(0, 0, 255), thickness=2)\n",
    "    \n",
    "    out.write(frame)\n",
    "    \n",
    "    # Display is commented out (uncomment if running in an environment with GUI support)\n",
    "    # cv2.imshow(\"Overlay with Trajectories\", frame)\n",
    "    # if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "    #     break\n",
    "    \n",
    "    frame_idx += 1\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "# cv2.destroyAllWindows()  # Commented out to avoid GUI errors.\n",
    "\n",
    "print(f\"Output video with trajectories saved to: {output_video_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
