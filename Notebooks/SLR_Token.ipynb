{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'body': array([0.5133897 , 0.39745952]), 'hands': array([0.53476158, 0.52073028]), 'face': array([0.5347218, 0.4757175])}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def encode_body_pose(body_keypoints):\n",
    "    # Custom encoding logic for body pose keypoints\n",
    "    return np.mean(body_keypoints, axis=0)  # Example: Mean of body keypoints\n",
    "\n",
    "def encode_hand_details(hand_keypoints):\n",
    "    # Custom encoding logic for hand keypoints\n",
    "    return np.mean(hand_keypoints, axis=0)  # Example: Mean of hand keypoints\n",
    "\n",
    "def encode_facial_expression(face_keypoints):\n",
    "    # Custom encoding logic for face keypoints\n",
    "    return np.mean(face_keypoints, axis=0)  # Example: Mean of face keypoints\n",
    "\n",
    "def hierarchical_tokenization(keypoints):\n",
    "    # Full body keypoints\n",
    "    body_tokens = encode_body_pose(keypoints['body'])\n",
    "    \n",
    "    # Hand keypoints (higher resolution)\n",
    "    hand_tokens = encode_hand_details(keypoints['hands'])\n",
    "    \n",
    "    # Facial expression keypoints\n",
    "    face_tokens = encode_facial_expression(keypoints['face'])\n",
    "    \n",
    "    return {\n",
    "        'body': body_tokens,\n",
    "        'hands': hand_tokens,\n",
    "        'face': face_tokens\n",
    "    }\n",
    "\n",
    "# Example input keypoints dictionary\n",
    "keypoints = {\n",
    "    'body': np.random.rand(17, 2),    # Assuming 17 keypoints for body\n",
    "    'hands': np.random.rand(21, 2),   # Assuming 21 keypoints for hands\n",
    "    'face': np.random.rand(68, 2)     # Assuming 68 keypoints for face\n",
    "}\n",
    "\n",
    "# Tokenize keypoints\n",
    "tokens = hierarchical_tokenization(keypoints)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Loss: [179.70439501 195.45743981 168.69579873 175.56042109 195.9127067\n",
      " 179.34880646 182.3638538  177.7655953  188.90251865 182.07707673]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def custom_loss(y_true, y_pred, token_weights):\n",
    "    # Classification loss\n",
    "    classification_loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "    \n",
    "    # Temporal continuity loss (dummy function as placeholder)\n",
    "    continuity_loss = tf.reduce_sum(tf.square(y_pred[:, 1:] - y_pred[:, :-1]))  # Temporal difference\n",
    "\n",
    "    # Keypoint accuracy loss (dummy function as placeholder)\n",
    "    keypoint_loss = tf.reduce_mean(tf.square(y_pred - y_true))\n",
    "    \n",
    "    return classification_loss + continuity_loss + keypoint_loss\n",
    "\n",
    "# Example usage\n",
    "y_true = np.random.rand(10, 50)  # Example true labels\n",
    "y_pred = np.random.rand(10, 50)  # Example predictions\n",
    "token_weights = 1.0  # Example token weights\n",
    "\n",
    "loss_value = custom_loss(y_true, y_pred, token_weights)\n",
    "print(\"Custom Loss:\", loss_value.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "object too deep for desired array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b1d5ef76e256>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mvideo_keypoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keypoints'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0maugmented_video_keypoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maugment_keypoints_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_keypoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0maugmented_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'keypoints'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maugmented_video_keypoints\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-b1d5ef76e256>\u001b[0m in \u001b[0;36maugment_keypoints_video\u001b[0;34m(video_keypoints, noise_level, viewpoint_shift, speed_variation)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mconfidences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     )\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36minterp\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/slt2/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36minterp\u001b[0;34m(x, xp, fp, left, right, period)\u001b[0m\n\u001b[1;32m   1421\u001b[0m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1423\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0minterp_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: object too deep for desired array"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Function to read pickle data\n",
    "def read_pkl(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "# Load the data\n",
    "path = '/nas/Dataset/Phoenix/phoenix-2014-keypoints.pkl'\n",
    "data = read_pkl(path)\n",
    "\n",
    "# Augmentation function adapted for the new data structure\n",
    "def augment_keypoints_video(video_keypoints, noise_level=0.01, viewpoint_shift=0.1, speed_variation=0.9):\n",
    "    num_frames, num_keypoints, _ = video_keypoints.shape\n",
    "    \n",
    "    # Separate x, y, and c components\n",
    "    xy_coords = video_keypoints[:, :, :2]\n",
    "    confidences = video_keypoints[:, :, 2]\n",
    "    \n",
    "    # Add Gaussian noise to x, y coordinates\n",
    "    noise = np.random.normal(0, noise_level, xy_coords.shape)\n",
    "    augmented_xy = xy_coords + noise\n",
    "    \n",
    "    # Apply viewpoint transformation (scaling)\n",
    "    scale_factor = 1 + viewpoint_shift * (np.random.rand() * 2 - 1)\n",
    "    augmented_xy *= scale_factor\n",
    "    \n",
    "    # Speed variation by interpolating along the time axis for each keypoint\n",
    "    new_length = int(num_frames * speed_variation)\n",
    "    augmented_xy_interpolated = np.zeros((new_length, num_keypoints, 2))\n",
    "    \n",
    "    for k in range(num_keypoints):\n",
    "        for dim in range(2):  # For x and y separately\n",
    "            augmented_xy_interpolated[:, k, dim] = np.interp(\n",
    "                np.linspace(0, num_frames - 1, new_length),\n",
    "                np.arange(num_frames),\n",
    "                augmented_xy[:, k, dim]\n",
    "            )\n",
    "    \n",
    "    # Combine augmented x, y with original confidences\n",
    "    augmented_video_keypoints = np.zeros((new_length, num_keypoints, 3))\n",
    "    augmented_video_keypoints[:, :, :2] = augmented_xy_interpolated\n",
    "    augmented_video_keypoints[:, :, 2] = np.interp(\n",
    "        np.linspace(0, num_frames - 1, new_length),\n",
    "        np.arange(num_frames),\n",
    "        confidences\n",
    "    )\n",
    "\n",
    "    return augmented_video_keypoints\n",
    "\n",
    "# Apply augmentation to the whole dataset\n",
    "augmented_data = {}\n",
    "for video, video_data in data.items():\n",
    "    video_keypoints = video_data['keypoints']\n",
    "    augmented_video_keypoints = augment_keypoints_video(video_keypoints)\n",
    "    augmented_data[video] = {'keypoints': augmented_video_keypoints}\n",
    "\n",
    "# Example: Check the shape of augmented data for a sample video\n",
    "sample_video = list(augmented_data.keys())[0]\n",
    "print(\"Original shape:\", data[sample_video]['keypoints'].shape)\n",
    "print(\"Augmented shape:\", augmented_data[sample_video]['keypoints'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example function to integrate everything\n",
    "def process_and_train_model(data_input, model, optimizer):\n",
    "    augmented_data = augment_keypoints(data_input)\n",
    "    tokens = hierarchical_tokenization(augmented_data)\n",
    "    \n",
    "    # Pass tokens through the model\n",
    "    y_pred = model(tokens)\n",
    "    \n",
    "    # Assume y_true is available\n",
    "    y_true = np.random.rand(*y_pred.shape)  # Placeholder for ground truth\n",
    "    \n",
    "    # Compute custom loss\n",
    "    loss = custom_loss(y_true, y_pred, token_weights=1.0)\n",
    "    \n",
    "    # Perform gradient descent\n",
    "    with tf.GradientTape() as tape:\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    print(\"Training step completed with loss:\", loss.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slt2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
